{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset import KinQueryDataset, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _batch_loader(iterable, n=1):\n",
    "    \"\"\"\n",
    "    데이터를 배치 사이즈만큼 잘라서 보내주는 함수입니다. PyTorch의 DataLoader와 같은 역할을 합니다\n",
    "\n",
    "    :param iterable: 데이터 list, 혹은 다른 포맷\n",
    "    :param n: 배치 사이즈\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    length = len(iterable)\n",
    "    for n_idx in range(0, length, n):\n",
    "        yield iterable[n_idx:min(n_idx + n, length)]\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shaep (?, 200)\n",
      "output shaep (?, 10)\n",
      "lables shaep (?, 10)\n"
     ]
    }
   ],
   "source": [
    "# User options\n",
    "batch = 1\n",
    "epochs = 1\n",
    "\n",
    "embedding = 30\n",
    "strmaxlen = 200\n",
    "DATASET_PATH = '../sample_data/movie_review/'\n",
    "\n",
    "# 모델의 specification\n",
    "input_size = embedding*strmaxlen\n",
    "output_size = 10\n",
    "hidden_layer_size = 200\n",
    "learning_rate = 0.001\n",
    "character_size = 251\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, strmaxlen])\n",
    "y_ = tf.placeholder(tf.float32, [None, output_size])\n",
    "# 임베딩\n",
    "char_embedding = tf.get_variable('char_embedding', [character_size, embedding])\n",
    "embedded = tf.nn.embedding_lookup(char_embedding, x)\n",
    "\n",
    "# 첫 번째 레이어\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer_size)\n",
    "cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=0.9)\n",
    "#tf.cast(cell, tf.int32)\n",
    "#tf.cast(x, tf.int32)\n",
    "\n",
    "output, state = tf.nn.dynamic_rnn(cell, embedded, dtype=tf.float32)\n",
    "output = tf.transpose(output, [1, 0, 2])\n",
    "output = output[-1]\n",
    "print(\"output shaep\",output.shape)\n",
    "\n",
    "# 두 번째 (아웃풋) 레이어\n",
    "second_layer_weight = weight_variable([hidden_layer_size, output_size])\n",
    "second_layer_bias = bias_variable([output_size])\n",
    "output = tf.matmul(output, second_layer_weight) + second_layer_bias\n",
    "#output_sigmoid = tf.sigmoid(output)\n",
    "print(\"output shaep\",output.shape)\n",
    "print(\"lables shaep\",y_.shape)\n",
    "# loss와 optimizer\n",
    "#global_step = tf.Variable(0)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y_))\n",
    "#ls = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_, predictions=output))\n",
    "ls = tf.reduce_mean(tf.square(output-y_))\n",
    "\n",
    "#print(loss)\n",
    "\n",
    "#learning_rate= tf.train.exponential_decay(learning_rate, global_step, 10000, 0.75)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(ls)\n",
    "#train_step = tf.train.AdadeltaOptimizer(1.0, 0.95, 1e-6).minimize(cost)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = KinQueryDataset(DATASET_PATH, strmaxlen)\n",
    "dataset_len = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "print(dataset_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(2)[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_one_hot(labels):\n",
    "    one_hot = (np.arange(output_size) == labels[:]).astype(np.int32)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_one_hot([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09317937  0.06905934  0.14501873  0.06492354  0.08705307  0.09487598\n",
      "   0.11142266  0.14549312  0.13151973  0.12215553]]\n",
      "[[ 0.02473442  0.07149015  0.12236015  0.06597787  0.05370649  0.19037379\n",
      "   0.10811619  0.09205828  0.0746674   0.11529785]]\n",
      "[[ 0.0391154   0.03739097  0.0912198   0.06758422  0.04401446  0.19891334\n",
      "   0.09024289  0.15181908  0.07992584  0.11402007]]\n",
      "[[ 0.01690291  0.04172587  0.05041428  0.02973522  0.0179518   0.22341949\n",
      "   0.06588715  0.18100372  0.04418751  0.08373076]]\n",
      "[[ 0.00582891  0.02172139  0.03172526  0.05002946 -0.01384088  0.18829924\n",
      "  -0.00545477  0.17201346  0.05207273  0.02130491]]\n",
      "[[ 0.00393488 -0.02390866 -0.01511571 -0.00306205  0.01454236  0.16549426\n",
      "  -0.04366522  0.1824078   0.01956982  0.00744063]]\n",
      "[[-0.0348107  -0.04801531 -0.04563063 -0.01182494 -0.01058286  0.13394311\n",
      "  -0.07029643  0.17144272  0.01433792 -0.02799732]]\n",
      "[[-0.03786    -0.01621224 -0.01772789  0.01060659  0.01339936  0.10779733\n",
      "  -0.06315109  0.14366224  0.05002035 -0.02251859]]\n",
      "[[ 0.01343346 -0.04978795 -0.02695347 -0.00962299 -0.00058953  0.07501607\n",
      "  -0.02697159  0.12940675  0.01931722 -0.04598262]]\n",
      "[[-0.01623826 -0.05128485 -0.05516364  0.00857262  0.02261278  0.04839358\n",
      "  -0.02241048  0.07203342 -0.01511285 -0.0105821 ]]\n",
      "[[ 0.01313942  0.00684965 -0.01874582 -0.01946738  0.04389145  0.02222235\n",
      "  -0.01560059  0.05060187 -0.01776638 -0.00459689]]\n",
      "[[ 0.0174429   0.01631047  0.03604994  0.00559687  0.04117907  0.01667403\n",
      "   0.01110491  0.01714957 -0.01989638 -0.01569431]]\n",
      "[[-0.0104863  -0.0124362  -0.00578375  0.00720879  0.01098569 -0.00627759\n",
      "  -0.00127334 -0.01150997 -0.02434747 -0.01481809]]\n",
      "[[ 0.0267674   0.00912407 -0.00081798  0.01756302  0.00530751 -0.00011837\n",
      "  -0.0059306  -0.03002406 -0.00139169  0.02366424]]\n",
      "[[ 0.01898547 -0.01346631  0.02100497  0.00811783  0.01751863 -0.03428698\n",
      "   0.03496149 -0.06903391  0.00055762  0.02724458]]\n",
      "[[-0.00520778  0.01445995  0.01786071  0.03132732 -0.02959869 -0.02708382\n",
      "   0.02331469 -0.07366329  0.01079889  0.01295345]]\n",
      "[[ 0.01917094  0.01509538  0.03470748  0.00800291 -0.01764034 -0.03753424\n",
      "   0.02232879 -0.0472343   0.0403126   0.03292273]]\n",
      "[[ 0.00457346  0.00641916  0.02348659  0.0237329  -0.000845   -0.03583182\n",
      "   0.02099755 -0.03015287  0.04655632  0.03216334]]\n",
      "[[-0.00164904  0.02791651  0.01468178  0.00749798  0.00582143 -0.01609339\n",
      "   0.03341939 -0.0488525   0.00488335 -0.0052484 ]]\n",
      "[[ 0.01853441  0.01058172  0.0185293   0.01634627 -0.02905946 -0.02395616\n",
      "   0.02403405 -0.03286175  0.0086996  -0.00458606]]\n",
      "[[ 0.01936072  0.03308981  0.03783993 -0.00031897  0.01353992  0.0006409\n",
      "   0.02263675 -0.02625514  0.02637471  0.01684706]]\n",
      "[[ 0.02946187  0.01101887  0.01671737  0.01835557  0.0092178  -0.0180787\n",
      "   0.02311881 -0.0012323   0.00382794  0.01142113]]\n",
      "[[-0.02488998  0.04048664 -0.01198792 -0.00890367 -0.00523178  0.00179844\n",
      "  -0.00086431  0.01386338 -0.00457077  0.02980798]]\n",
      "[[-0.00135537  0.01891456 -0.01898555  0.01136208 -0.00866382 -0.00956862\n",
      "   0.01649564 -0.00387245 -0.01649927 -0.01680519]]\n",
      "[[ 0.00323594  0.00517269  0.00679227 -0.00211032 -0.01498844 -0.01184767\n",
      "  -0.01609836  0.01045897 -0.03164805 -0.00214498]]\n",
      "[[-0.00730513 -0.02284127  0.00333191 -0.00734659 -0.04069216 -0.00765922\n",
      "  -0.01022188 -0.00013453 -0.02326968  0.01337792]]\n",
      "[[ 0.0176056   0.00672046  0.02175207 -0.02405892 -0.00901927  0.00197823\n",
      "  -0.00947798  0.03711059 -0.01398596  0.00220904]]\n",
      "[[-0.01766936  0.01091596  0.00399394 -0.03254334 -0.00229672  0.00364015\n",
      "  -0.01749521  0.02624177 -0.00105    -0.00068393]]\n",
      "[[-0.00205115 -0.01595844 -0.01643689 -0.01273653 -0.01541409 -0.00352555\n",
      "   0.0003614   0.01602557 -0.01558974 -0.02540103]]\n",
      "[[ 0.01696091 -0.01199459 -0.00717393 -0.01340996  0.01357862  0.01318184\n",
      "  -0.02168402  0.02220357  0.01237366 -0.00817653]]\n",
      "[[-0.00866874 -0.01647525 -0.01886631  0.00024129  0.01558516  0.01033399\n",
      "  -0.02917576  0.01151164  0.00217496 -0.00911988]]\n",
      "[[-0.00610369 -0.01355352 -0.01269731  0.01888306  0.02074291  0.00979405\n",
      "  -0.0211956   0.01977985  0.01189144  0.00883223]]\n",
      "[[-0.01186839 -0.00965764 -0.02086249  0.00473787  0.02690688  0.0216191\n",
      "   0.01621914  0.01222835  0.02123468 -0.00550831]]\n",
      "[[-0.00453297 -0.005174   -0.00015434  0.0223068   0.03178109  0.01246373\n",
      "   0.03255509  0.01691888  0.01762041  0.01433177]]\n",
      "[[-0.00446098 -0.01326632 -0.00546429  0.01404551  0.01129513  0.02486482\n",
      "   0.00767397  0.01291963  0.00840234 -0.00562551]]\n",
      "[[-0.00816466  0.00295432 -0.01365253  0.00049674 -0.00383773  0.01883123\n",
      "   0.00751194  0.01782909  0.01133154  0.0054916 ]]\n",
      "[[-0.01791396 -0.01637148 -0.00443612 -0.00227978  0.00649148  0.00418913\n",
      "   0.00474408  0.02204272  0.00687222  0.00647071]]\n",
      "[[-0.00667762  0.02082229  0.013234   -0.00831269  0.01699024  0.00758333\n",
      "  -0.00799552  0.01819028  0.0080786   0.01269542]]\n",
      "[[ 0.0203056  -0.00017842  0.00604855 -0.01099812  0.00216338  0.02621911\n",
      "  -0.00259518 -0.00058472 -0.01191992 -0.00599842]]\n",
      "[[ 0.00843562 -0.00826509  0.01294649 -0.00793665 -0.00798404  0.00815344\n",
      "  -0.0021873   0.01292261  0.00311691 -0.02462538]]\n",
      "[[-0.00331944 -0.02000467 -0.00212681 -0.00083833 -0.00571451  0.01523232\n",
      "  -0.00711232 -0.01819523 -0.02469507 -0.01130228]]\n",
      "[[ 0.02948994 -0.01309013  0.00174426  0.00330014 -0.00092148  0.00625057\n",
      "  -0.01147276  0.00651234 -0.00788319 -0.00140771]]\n",
      "[[-0.01228155 -0.00885887 -0.01499063  0.00274194 -0.0045749   0.00065185\n",
      "  -0.01176161  0.00349785 -0.0024975  -0.0064152 ]]\n",
      "[[ 0.00225621 -0.00475246  0.00253178  0.01407088 -0.01969256 -0.01298644\n",
      "   0.00198437  0.01072597 -0.01864262 -0.01932185]]\n",
      "[[ 0.00719148  0.056506    0.0044786   0.00536968 -0.00424724  0.02750311\n",
      "  -0.02444901 -0.01826466 -0.01602244  0.00239733]]\n",
      "[[ 0.0217412   0.07680856  0.00732177  0.02651623  0.01866503  0.02161855\n",
      "   0.05623135  0.02227318  0.00444929 -0.00041845]]\n",
      "[[-0.00426419  0.09315275 -0.02323965  0.0133171   0.00281809  0.01130123\n",
      "   0.06660224  0.01804931  0.0076184   0.02431511]]\n",
      "[[ 0.01647892  0.0961659  -0.02841433  0.01123767  0.01221205  0.02555078\n",
      "   0.08036733  0.02315271  0.01885497  0.06005178]]\n",
      "[[ 0.02465557  0.09247545 -0.02460691  0.01917317  0.00533681  0.02497873\n",
      "   0.08439138  0.02727658  0.01606151  0.09227061]]\n",
      "[[ 0.00808785  0.10326186 -0.02021978  0.02127549 -0.00032037  0.028577\n",
      "   0.11618612  0.02752784  0.01573557  0.10145645]]\n",
      "[[-0.0078064   0.10219646 -0.02036533  0.00932056  0.00826658  0.01715462\n",
      "   0.11972855  0.02815659  0.03126499  0.09527692]]\n",
      "[[ 0.01186831  0.09572276 -0.01260326  0.02298916  0.01825865  0.03543908\n",
      "   0.12020604  0.03477518  0.03569068  0.11732435]]\n",
      "[[ 0.00594154  0.0850707  -0.01322364  0.01442581  0.00537423  0.01970877\n",
      "   0.11863983  0.03174241  0.01765612  0.1124415 ]]\n",
      "[[ 0.02096704  0.06780744  0.00702328  0.02404957 -0.00797897  0.01262973\n",
      "   0.10694993  0.02813505  0.03117274  0.10378145]]\n",
      "[[ 0.01103657  0.04631692  0.0004988   0.0186797   0.00365242  0.00781264\n",
      "   0.11101706  0.02439928  0.01591854  0.1143184 ]]\n",
      "[[ 0.01607171  0.05641937  0.02217718  0.0016733  -0.01488348  0.01437076\n",
      "   0.07754479  0.00803649  0.02279337  0.10062338]]\n",
      "[[ 0.01269802  0.03358896  0.02225809 -0.00410359 -0.0199917  -0.00104908\n",
      "   0.0790619   0.02458707  0.01789401  0.09183522]]\n",
      "[[ 0.00407671  0.03537016  0.02005447 -0.01227123 -0.02009016  0.00170071\n",
      "   0.06386252  0.01774301  0.00877878  0.0793268 ]]\n",
      "[[-0.00615254  0.03315476  0.03390565 -0.01822421 -0.01325253  0.00287994\n",
      "   0.02782751  0.00728715  0.00601204  0.0738093 ]]\n",
      "[[ 0.00864463  0.02106109  0.02404621 -0.0122702  -0.04569044  0.00463359\n",
      "   0.00642387  0.00538976 -0.00376008  0.05169079]]\n",
      "[[-0.01567295  0.01466448  0.0361183   0.00476891 -0.02294696  0.00641508\n",
      "   0.01843116  0.01059609 -0.01255329  0.03647299]]\n",
      "[[-0.00173483  0.02327176  0.0346101  -0.01315113 -0.01951139  0.00301741\n",
      "   0.02481529  0.01323467 -0.01087745  0.0391475 ]]\n",
      "[[-0.00701609  0.00305491  0.024104   -0.00179744 -0.03414219 -0.00961082\n",
      "   0.0021079  -0.00360439 -0.00962682  0.01972287]]\n",
      "[[-0.00872891 -0.01130494 -0.00504601  0.00575788 -0.03734334 -0.02508417\n",
      "  -0.00280222  0.00187688 -0.00051385 -0.00045507]]\n",
      "[[  1.05026439e-02  -1.84340253e-02   1.02892816e-02  -2.02526972e-02\n",
      "   -1.06225163e-03  -3.38565707e-02  -8.94559175e-03  -3.08901072e-05\n",
      "    2.41711736e-03   3.48813832e-03]]\n",
      "[[-0.01363925 -0.00477983 -0.00287466 -0.00641385  0.01267922 -0.00281574\n",
      "   0.00116955 -0.00786529 -0.01472026 -0.0084129 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00990265  0.0005295   0.01374606 -0.01547445  0.0175954  -0.0046103\n",
      "  -0.02241769 -0.02076409  0.00302655  0.01530813]]\n",
      "[[ 0.01053747  0.00047559 -0.00045329  0.01075107  0.02697458 -0.00793052\n",
      "   0.00570326 -0.0051332  -0.00076134 -0.00760055]]\n",
      "[[ 0.0308515   0.05110308 -0.00270513  0.02360534  0.01889315  0.01612415\n",
      "  -0.0266325   0.01134675  0.03443271 -0.01453704]]\n",
      "[[ 0.00148254  0.09545395  0.0092511   0.03173648  0.05575669  0.02547744\n",
      "  -0.03007405  0.00522115  0.12610182 -0.02363237]]\n",
      "[[-0.01311142  0.08010703  0.0126396   0.01716281  0.03775664  0.00462386\n",
      "  -0.0072839   0.01623014  0.15433212 -0.02356572]]\n",
      "[[-0.0214399   0.09894601  0.01214742  0.02342603  0.05990922  0.02758168\n",
      "  -0.00587254  0.01315174  0.18704978 -0.0131316 ]]\n",
      "[[-0.00339919  0.09692983  0.03580248  0.01267479  0.05593323  0.02733994\n",
      "  -0.01522077  0.02134204  0.20509648 -0.00734536]]\n",
      "[[-0.00699548  0.11072253  0.01846363  0.02339452  0.05103736  0.01435227\n",
      "  -0.00290303  0.01603802  0.21825284 -0.00902853]]\n",
      "[[-0.00752162  0.0803474   0.01517019  0.0156666   0.03159704  0.0193907\n",
      "   0.00121947  0.02899554  0.20232877 -0.00246549]]\n",
      "[[-0.00963677  0.06880845  0.03114012  0.02179844  0.02798184  0.02971076\n",
      "   0.02263848  0.04043199  0.18505761  0.02491146]]\n",
      "[[ 0.01117184  0.08749821  0.04360262  0.01170862  0.03302391  0.03558144\n",
      "   0.02000473  0.03683101  0.18271258  0.04151276]]\n",
      "[[ 0.01173349  0.06780438  0.01461823  0.01554811  0.01619132  0.03215871\n",
      "   0.00952896  0.02876772  0.16772094  0.05747795]]\n",
      "[[ 0.02092039  0.06104628  0.01041029  0.01322409  0.00861441  0.03451464\n",
      "   0.00055803  0.0351975   0.15020552  0.06836765]]\n",
      "[[ 0.03792011  0.05498067  0.02618849  0.00969604  0.00335675  0.0409583\n",
      "   0.00474972  0.02941152  0.13582614  0.07819974]]\n",
      "[[ 0.05235504  0.06606356  0.00775117 -0.00388799  0.01277846  0.02712809\n",
      "  -0.00036459  0.0304941   0.12165196  0.08680439]]\n",
      "[[ 0.07511865  0.08065517  0.01340865  0.00053024  0.03047609  0.03929216\n",
      "   0.00623275  0.02957635  0.10830148  0.08765512]]\n",
      "[[ 0.08293382  0.12034053  0.01709988 -0.01362696  0.01936679  0.04473253\n",
      "   0.00371246  0.02602725  0.07892095  0.08345513]]\n",
      "[[ 0.08039791  0.16448691  0.00876608 -0.0119231   0.03828032  0.03970829\n",
      "   0.00775914  0.02059677  0.07414301  0.0812551 ]]\n",
      "[[ 0.07836186  0.19202158  0.00447339 -0.00998155  0.02871044  0.04258262\n",
      "  -0.00982956  0.01210395  0.05886552  0.07824827]]\n",
      "[[ 0.09746333  0.21526635  0.01336306  0.03745585  0.03623439  0.05786086\n",
      "   0.00680196  0.02306999  0.07334606  0.05919928]]\n",
      "[[ 0.11027539  0.2078512   0.02526939  0.05058314  0.02387473  0.08222006\n",
      "   0.00359096  0.04052773  0.04397371  0.06445918]]\n",
      "[[ 0.09259108  0.22517604  0.01637696  0.07556449  0.02403988  0.09225734\n",
      "   0.01191741  0.04512479  0.04330049  0.05310792]]\n",
      "[[ 0.06739846  0.23422451  0.02587944  0.08942769  0.02437118  0.0954982\n",
      "   0.01841033  0.06266534  0.05620361  0.05236737]]\n",
      "[[ 0.08924413  0.23064178  0.0175712   0.09110767  0.02288196  0.10357947\n",
      "   0.02083962  0.07679844  0.06310914  0.04997429]]\n",
      "[[ 0.06499732  0.20695859  0.02408971  0.08411482  0.01463663  0.09271117\n",
      "   0.02645276  0.07031197  0.06010927  0.03360377]]\n",
      "[[ 0.069198    0.21054353  0.02255072  0.08175132  0.01191246  0.09844334\n",
      "   0.02234212  0.07803361  0.07333358  0.03998716]]\n",
      "[[ 0.05320527  0.2009974   0.02365713  0.08564252  0.00548389  0.08292378\n",
      "   0.03108013  0.08051649  0.06700923  0.03279468]]\n",
      "[[ 0.05148781  0.17616752  0.02212266  0.09135273  0.01981976  0.09594472\n",
      "   0.04566068  0.09152766  0.06625321  0.02916846]]\n",
      "[[ 0.04925172  0.18211913  0.0115765   0.07741481 -0.00936193  0.08492652\n",
      "   0.03531524  0.09020986  0.06175365  0.01399015]]\n",
      "[[ 0.03571347  0.16748492  0.00223207  0.06663226 -0.01578333  0.0751214\n",
      "   0.0372889   0.08978371  0.06151785  0.01421311]]\n",
      "[[ 0.03312701  0.15755115  0.01764958  0.08143548  0.00037802  0.07574865\n",
      "   0.05992976  0.0937345   0.06186426  0.03972434]]\n",
      "[[ 0.03100367  0.14824873  0.02089752  0.06074454 -0.01933394  0.06037724\n",
      "   0.03497022  0.07241169  0.06543631  0.01235031]]\n",
      "[[ 0.02017841  0.12963696  0.00436739  0.06246642 -0.01424181  0.06800173\n",
      "   0.04943186  0.07921783  0.05977902  0.02212803]]\n",
      "[[ 0.00034624  0.13466524  0.00120065  0.04199579 -0.03338221  0.05310969\n",
      "   0.0319526   0.07387698  0.05284013  0.00247911]]\n",
      "[[ 0.00485178  0.12517986  0.01016191  0.03045119 -0.01538195  0.07945583\n",
      "   0.05288051  0.06689624  0.04312469  0.01161996]]\n",
      "[[-0.00596477  0.13866694  0.00953102  0.0218982  -0.02255658  0.05362689\n",
      "   0.03105139  0.06490307  0.06423175  0.00494377]]\n",
      "[[-0.02005824  0.12692589 -0.0005808   0.00275663 -0.02067052  0.04513859\n",
      "   0.02701481  0.05341319  0.04464033 -0.00877001]]\n",
      "[[-0.02195354  0.13184848 -0.02953902  0.00653245 -0.01442067  0.03697539\n",
      "   0.01431069  0.05559938  0.0506533   0.00406282]]\n",
      "[[-0.02308369  0.11948042 -0.00787342  0.01580387 -0.02191593  0.03437428\n",
      "   0.00612403  0.03927932  0.04933164 -0.0045853 ]]\n",
      "[[-0.01249991  0.12163885 -0.01225065 -0.00782026 -0.00706428  0.01239068\n",
      "   0.01485917  0.05392709  0.03994909 -0.00542142]]\n",
      "[[-0.04144368  0.11646701 -0.03171453 -0.02938139 -0.01709935  0.02491622\n",
      "   0.02167843  0.03487935  0.02907415 -0.00356738]]\n",
      "epoch: 0  train_loss: 0.4087120305711978 0.01914960738587265 0m 9s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "#batch = 1\n",
    "dataset = KinQueryDataset(DATASET_PATH, strmaxlen)\n",
    "dataset_len = len(dataset)\n",
    "one_batch_size = dataset_len//batch\n",
    "if dataset_len % batch != 0:\n",
    "    one_batch_size += 1\n",
    "# epoch마다 학습을 수행합니다.\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0.0\n",
    "    avg_l=0.0\n",
    "    for i, (data, labels) in enumerate(_batch_loader(dataset, batch)):\n",
    "        #zero = np.zeros([batch,1])\n",
    "        #zero[0] = \n",
    "        _, loss, l,o = sess.run([train_step, cost, ls,output],\n",
    "                           feed_dict={x: data, y_: label_one_hot(labels)})\n",
    "        if math.isnan(loss):\n",
    "            print('Detected NaN')\n",
    "            import pdb; pdb.set_trace()\n",
    "        #print('Batch : ', i + 1, '/', one_batch_size,', BCE in this minibatch: ', (loss))\n",
    "        avg_loss += float(loss)\n",
    "        avg_l += float(l)\n",
    "        print(o)\n",
    "    print('epoch:', epoch, ' train_loss:', float(avg_loss/one_batch_size),float(avg_l/one_batch_size),timeSince(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.]\n"
     ]
    }
   ],
   "source": [
    "#ze = np.zeros([batch,2])\n",
    "#ze[0,0] = 1\n",
    "ze = np.zeros([2])\n",
    "ze[0] = 1\n",
    "\n",
    "print(ze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.]\n",
      "[ 7.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 1.]\n",
      "[ 6.]\n",
      "[ 9.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 1.]\n",
      "[ 8.]\n",
      "[ 8.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 9.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 0.]\n",
      "[ 1.]\n",
      "[ 1.]\n",
      "[ 1.]\n",
      "[ 1.]\n",
      "[ 3.]\n",
      "[ 5.]\n",
      "[ 7.]\n",
      "[ 8.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 1.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n",
      "[ 10.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i, (data, labels) in enumerate(_batch_loader(dataset, batch)):\n",
    "    #t = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #            logits=ze, labels=one(labels))\n",
    "    for i in range(batch):\n",
    "        print(labels[i])\n",
    "    #print(one(labels), ze, t.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "o=np.array([[0]])\n",
    "o[0,0]\n",
    "idx = np.argmax(o,axis=0)\n",
    "print(o[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-5a677b5d0595>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-5a677b5d0595>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    n = np.ndarray([,2])\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "n = np.ndarray([,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
